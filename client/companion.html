<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Annabeth - Desktop Companion</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        html, body {
            background: transparent !important;
            background-color: rgba(0,0,0,0) !important;
            overflow: hidden;
            width: 100%;
            height: 100%;
        }
        
        #canvas-container { 
            width: 100vw; 
            height: 100vh;
            background: transparent !important;
            background-color: rgba(0,0,0,0) !important;
        }
        
        canvas {
            background: transparent !important;
            background-color: rgba(0,0,0,0) !important;
        }
        
        /* Small status indicator */
        #mini-status {
            position: fixed;
            bottom: 10px;
            left: 50%;
            transform: translateX(-50%);
            color: rgba(255,255,255,0.7);
            font-family: 'Segoe UI', sans-serif;
            font-size: 11px;
            padding: 4px 10px;
            border-radius: 10px;
            background: rgba(0,0,0,0.3);
            opacity: 0;
            transition: opacity 0.3s;
            pointer-events: none;
        }
        
        #mini-status.visible {
            opacity: 1;
        }
        
        /* Subtitle for speech */
        #subtitle {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            color: #fff;
            background: rgba(0,0,0,0.7);
            padding: 8px 16px;
            border-radius: 8px;
            font-family: 'Segoe UI', sans-serif;
            font-size: 12px;
            max-width: 90%;
            text-align: center;
            opacity: 0;
            transition: opacity 0.3s;
            pointer-events: none;
        }
        
        #subtitle.visible {
            opacity: 1;
        }
        
        /* Drag handle at top of window */
        #drag-handle {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            height: 30px;
            cursor: move;
            background: linear-gradient(to bottom, rgba(0,0,0,0.3) 0%, rgba(0,0,0,0) 100%);
            z-index: 1000;
            display: flex;
            justify-content: center;
            align-items: center;
            opacity: 0;
            transition: opacity 0.3s;
        }
        
        #drag-handle:hover {
            opacity: 1;
        }
        
        #drag-handle span {
            color: rgba(255,255,255,0.7);
            font-family: 'Segoe UI', sans-serif;
            font-size: 10px;
        }
    </style>
    <!-- QWebChannel for Python communication -->
    <script src="qrc:///qtwebchannel/qwebchannel.js"></script>
</head>
<body>
    <div id="drag-handle"><span>â‹®â‹® drag to move â‹®â‹®</span></div>
    <div id="canvas-container"></div>
    <div id="mini-status">ðŸ”Œ Connecting...</div>
    <div id="subtitle"></div>

    <script>
        // Initialize QWebChannel for Python communication
        window.pyBridge = null;
        
        if (typeof QWebChannel !== 'undefined') {
            new QWebChannel(qt.webChannelTransport, function(channel) {
                window.pyBridge = channel.objects.pyBridge;
                console.log('QWebChannel connected');
            });
        }
        
        // Window dragging via QWebChannel
        let isDragging = false;
        let dragStartX = 0;
        let dragStartY = 0;
        
        const dragHandle = document.getElementById('drag-handle');
        
        dragHandle.addEventListener('mousedown', (e) => {
            if (e.button === 0) {  // Left click
                isDragging = true;
                dragStartX = e.screenX;
                dragStartY = e.screenY;
                e.preventDefault();
            }
        });
        
        document.addEventListener('mousemove', (e) => {
            if (isDragging && window.pyBridge) {
                const deltaX = e.screenX - dragStartX;
                const deltaY = e.screenY - dragStartY;
                dragStartX = e.screenX;
                dragStartY = e.screenY;
                window.pyBridge.moveWindow(deltaX, deltaY);
            }
        });
        
        document.addEventListener('mouseup', (e) => {
            isDragging = false;
        });
        
        // Also allow right-click anywhere to drag
        document.addEventListener('contextmenu', (e) => {
            e.preventDefault();  // Prevent context menu
        });
        
        let rightDragging = false;
        document.addEventListener('mousedown', (e) => {
            if (e.button === 2) {  // Right click
                rightDragging = true;
                dragStartX = e.screenX;
                dragStartY = e.screenY;
                e.preventDefault();
            }
        });
        
        document.addEventListener('mousemove', (e) => {
            if (rightDragging && window.pyBridge) {
                const deltaX = e.screenX - dragStartX;
                const deltaY = e.screenY - dragStartY;
                dragStartX = e.screenX;
                dragStartY = e.screenY;
                window.pyBridge.moveWindow(deltaX, deltaY);
            }
        });
        
        document.addEventListener('mouseup', (e) => {
            if (e.button === 2) {
                rightDragging = false;
            }
        });
    </script>

    <script type="importmap">
    {
        "imports": {
            "three": "https://cdn.jsdelivr.net/npm/three@0.161.0/build/three.module.js",
            "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.161.0/examples/jsm/",
            "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@2.1.0/lib/three-vrm.module.min.js"
        }
    }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';
        
        // Try to load VRMA support (optional)
        let VRMAnimationLoaderPlugin = null;
        let createVRMAnimationClip = null;
        try {
            const vrmAnimModule = await import('https://cdn.jsdelivr.net/npm/@pixiv/three-vrm-animation@2.1.0/lib/three-vrm-animation.module.min.js');
            VRMAnimationLoaderPlugin = vrmAnimModule.VRMAnimationLoaderPlugin;
            createVRMAnimationClip = vrmAnimModule.createVRMAnimationClip;
        } catch (e) {
            console.warn('VRMA animation support not available');
        }

        const statusEl = document.getElementById('mini-status');
        const subtitleEl = document.getElementById('subtitle');

        // Scene setup with transparent background
        const scene = new THREE.Scene();
        
        // Camera positioned for desktop companion view - larger, focused on face
        const camera = new THREE.PerspectiveCamera(30, window.innerWidth / window.innerHeight, 0.1, 100);
        camera.position.set(0, 1.35, -2.5);  // Closer and centered on face for better mouth visibility
        camera.lookAt(0, 1.3, 0);

        // Transparent renderer - crucial settings for pywebview transparency
        const renderer = new THREE.WebGLRenderer({ 
            antialias: true, 
            alpha: true,
            premultipliedAlpha: true
        });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.outputColorSpace = THREE.SRGBColorSpace;
        renderer.setClearColor(0x000000, 0);  // Fully transparent
        renderer.domElement.style.background = 'transparent';
        document.getElementById('canvas-container').appendChild(renderer.domElement);

        // Lighting - brighter and more balanced for desktop companion
        const ambientLight = new THREE.AmbientLight(0xffffff, 1.2);
        scene.add(ambientLight);

        // Main front light - brighter, positioned in front
        const frontLight = new THREE.DirectionalLight(0xffffff, 1.5);
        frontLight.position.set(0, 2, -3);  // In front of avatar (camera side)
        scene.add(frontLight);

        // Fill light from side
        const fillLight = new THREE.DirectionalLight(0xffffff, 0.6);
        fillLight.position.set(2, 1, -1);
        scene.add(fillLight);

        // Subtle rim light from behind
        const rimLight = new THREE.DirectionalLight(0xaaccff, 0.4);
        rimLight.position.set(-1, 1, 2);
        scene.add(rimLight);

        // LookAt target (follows mouse - positioned in front of avatar toward camera)
        const lookAtTarget = new THREE.Object3D();
        scene.add(lookAtTarget);
        lookAtTarget.position.set(0, 1.0, -2.5);  // Match camera height

        let vrm = null;
        let isSpeaking = false;
        let currentEmotion = 'neutral';
        let targetEmotion = 'neutral';
        let emotionBlend = 0;
        
        // Blink state
        let blinkTimer = 0;
        let isBlinking = false;
        let nextBlinkTime = 2 + Math.random() * 3;
        
        // Idle animation state
        let idleTime = 0;
        let headIdlePhase = Math.random() * Math.PI * 2;
        let bodyIdlePhase = Math.random() * Math.PI * 2;
        
        // Lip sync state
        const vowels = ['aa', 'ih', 'ou', 'ee', 'oh'];
        let currentVowelIndex = 0;
        let vowelTimer = 0;

        // Animation system
        let mixer = null;
        let currentAction = null;
        const loadedAnimations = new Map();
        let isPlayingVRMA = false;
        
        // Load VRM
        const loader = new GLTFLoader();
        loader.register((parser) => new VRMLoaderPlugin(parser));
        if (VRMAnimationLoaderPlugin) {
            loader.register((parser) => new VRMAnimationLoaderPlugin(parser));
        }

        const vrmUrl = '/models/vrm/claire_avatar.vrm';
        
        loader.load(
            vrmUrl,
            (gltf) => {
                vrm = gltf.userData.vrm;
                if (!vrm) {
                    statusEl.textContent = 'âŒ Invalid VRM';
                    statusEl.classList.add('visible');
                    return;
                }
                VRMUtils.removeUnnecessaryVertices(gltf.scene);
                VRMUtils.removeUnnecessaryJoints(gltf.scene);
                scene.add(gltf.scene);
                
                // Setup lookAt
                if (vrm.lookAt) {
                    vrm.lookAt.target = lookAtTarget;
                    vrm.lookAt.autoUpdate = true;
                }
                
                setupIdlePose();
                mixer = new THREE.AnimationMixer(gltf.scene);
                
                statusEl.textContent = 'âœ… Ready';
                statusEl.classList.add('visible');
                setTimeout(() => statusEl.classList.remove('visible'), 2000);
                
                connectWebSocket();
            },
            (progress) => {
                const pct = Math.round((progress.loaded / progress.total) * 100);
                statusEl.textContent = `ðŸ“¦ ${pct}%`;
                statusEl.classList.add('visible');
            },
            (error) => {
                console.error('VRM load error:', error);
                statusEl.textContent = 'âŒ Load failed';
                statusEl.classList.add('visible');
            }
        );

        function setupIdlePose() {
            if (!vrm || !vrm.humanoid) return;
            
            const leftUpperArm = vrm.humanoid.getNormalizedBoneNode('leftUpperArm');
            const rightUpperArm = vrm.humanoid.getNormalizedBoneNode('rightUpperArm');
            
            if (leftUpperArm) leftUpperArm.rotation.z = 1.2;
            if (rightUpperArm) rightUpperArm.rotation.z = -1.2;
            
            const leftLowerArm = vrm.humanoid.getNormalizedBoneNode('leftLowerArm');
            const rightLowerArm = vrm.humanoid.getNormalizedBoneNode('rightLowerArm');
            
            if (leftLowerArm) leftLowerArm.rotation.z = 0.3;
            if (rightLowerArm) rightLowerArm.rotation.z = -0.3;
        }

        // WebSocket connection
        let ws = null;
        
        function connectWebSocket() {
            ws = new WebSocket('ws://127.0.0.1:8765/ws');
            
            ws.onopen = () => {
                console.log('WebSocket connected');
            };
            
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                handleMessage(data);
            };
            
            ws.onclose = () => {
                console.log('WebSocket closed, reconnecting...');
                setTimeout(connectWebSocket, 2000);
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
            };
        }

        function handleMessage(data) {
            switch(data.type) {
                case 'speak_start':
                    isSpeaking = true;
                    if (data.text) {
                        subtitleEl.textContent = data.text;
                        subtitleEl.classList.add('visible');
                    }
                    break;
                    
                case 'speak_end':
                    isSpeaking = false;
                    subtitleEl.classList.remove('visible');
                    break;
                    
                case 'emotion':
                    targetEmotion = data.emotion || 'neutral';
                    break;
            }
        }

        // Track mouse for lookAt (global screen position via pywebview)
        let mouseX = 0.5;
        let mouseY = 0.5;
        
        document.addEventListener('mousemove', (e) => {
            mouseX = e.clientX / window.innerWidth;
            mouseY = e.clientY / window.innerHeight;
        });

        // pywebview handles the window - drag not available without js_api
        // The window can be moved by grabbing the edges if pywebview supports it

        // Animation/render loop
        const clock = new THREE.Clock();
        
        function animate() {
            requestAnimationFrame(animate);
            
            const delta = clock.getDelta();
            idleTime += delta;
            
            if (vrm) {
                // Update lookAt based on mouse (negative Z for front-facing)
                const targetX = (mouseX - 0.5) * 2;
                const targetY = (0.5 - mouseY) * 1 + 1.0;
                lookAtTarget.position.lerp(
                    new THREE.Vector3(targetX, targetY, -2),
                    0.1
                );
                
                // Idle breathing/movement
                if (!isPlayingVRMA) {
                    applyIdleAnimation(delta);
                }
                
                // Blinking
                updateBlink(delta);
                
                // Lip sync when speaking
                if (isSpeaking) {
                    updateLipSync(delta);
                } else {
                    resetMouth();
                }
                
                // Emotion blending
                updateEmotions(delta);
                
                // Update VRM
                vrm.update(delta);
                
                // Update animation mixer
                if (mixer) mixer.update(delta);
            }
            
            renderer.render(scene, camera);
        }
        
        function applyIdleAnimation(delta) {
            if (!vrm || !vrm.humanoid) return;
            
            // Subtle breathing
            const spine = vrm.humanoid.getNormalizedBoneNode('spine');
            if (spine) {
                spine.rotation.x = Math.sin(idleTime * 0.8) * 0.01;
            }
            
            // Subtle head movement
            const head = vrm.humanoid.getNormalizedBoneNode('head');
            if (head) {
                head.rotation.y += Math.sin(idleTime * 0.3 + headIdlePhase) * 0.002;
                head.rotation.x += Math.sin(idleTime * 0.4 + headIdlePhase) * 0.001;
            }
        }
        
        function updateBlink(delta) {
            if (!vrm || !vrm.expressionManager) return;
            
            blinkTimer += delta;
            
            if (!isBlinking && blinkTimer >= nextBlinkTime) {
                isBlinking = true;
                blinkTimer = 0;
            }
            
            if (isBlinking) {
                const blinkProgress = blinkTimer / 0.15;
                
                if (blinkProgress < 0.5) {
                    vrm.expressionManager.setValue('blink', blinkProgress * 2);
                } else if (blinkProgress < 1) {
                    vrm.expressionManager.setValue('blink', (1 - blinkProgress) * 2);
                } else {
                    vrm.expressionManager.setValue('blink', 0);
                    isBlinking = false;
                    nextBlinkTime = 2 + Math.random() * 4;
                }
            }
        }
        
        function updateLipSync(delta) {
            if (!vrm || !vrm.expressionManager) return;
            
            vowelTimer += delta;
            
            if (vowelTimer >= 0.1) {
                vowelTimer = 0;
                currentVowelIndex = Math.floor(Math.random() * vowels.length);
            }
            
            // Reset all vowels
            vowels.forEach(v => {
                try { vrm.expressionManager.setValue(v, 0); } catch(e) {}
            });
            
            // Set current vowel
            try {
                vrm.expressionManager.setValue(vowels[currentVowelIndex], 0.6);
            } catch(e) {}
        }
        
        function resetMouth() {
            if (!vrm || !vrm.expressionManager) return;
            vowels.forEach(v => {
                try { vrm.expressionManager.setValue(v, 0); } catch(e) {}
            });
        }
        
        function updateEmotions(delta) {
            if (!vrm || !vrm.expressionManager) return;
            
            // Smooth emotion transition
            if (currentEmotion !== targetEmotion) {
                emotionBlend += delta * 2;
                if (emotionBlend >= 1) {
                    currentEmotion = targetEmotion;
                    emotionBlend = 0;
                }
            }
            
            const emotionMap = {
                'happy': 'happy',
                'sad': 'sad',
                'angry': 'angry',
                'surprised': 'surprised',
                'neutral': null
            };
            
            // Clear emotions first
            ['happy', 'sad', 'angry', 'surprised'].forEach(e => {
                try { vrm.expressionManager.setValue(e, 0); } catch(err) {}
            });
            
            // Apply current emotion
            if (emotionMap[currentEmotion]) {
                try {
                    vrm.expressionManager.setValue(emotionMap[currentEmotion], 0.7);
                } catch(err) {}
            }
        }
        
        // Handle window resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
        
        // Start animation
        animate();
    </script>
</body>
</html>
