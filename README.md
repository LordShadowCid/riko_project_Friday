# Project Riko

Project Riko is a anime focused LLM project by Just Rayen. She listens, and remembers your conversations. It combines OpenAIâ€™s GPT, GPT-SoVITS voice synthesis, and Faster-Whisper ASR into a fully configurable conversational pipeline.

**tested with python 3.10 Windows >10 and Linux Ubuntu**

## ğŸ§¾ Reference snapshots

This repo includes a `reference/` folder containing snapshots from before the upstream re-sync (kept for comparison and for reusing old code if needed):

- `reference/backup_pre_upstream_reset_2025-12-31/src/`: snapshot of the pre-reset branch
- `reference/stash_pre_upstream_reset_2025-12-31/`: snapshot of the pre-reset working tree (includes uncommitted changes)

## âœ¨ Features

- ğŸ’¬ **LLM-based dialogue** using OpenAI API (configurable system prompts)
- ğŸ§  **Conversation memory** to keep context during interactions
- ğŸ”Š **Voice generation** via GPT-SoVITS API
- ğŸ§ **Speech recognition** using Faster-Whisper
- ğŸ“ Clean YAML-based config for personality configuration


## âš™ï¸ Configuration

All prompts and parameters are stored in `character_config.yaml`.

```yaml
OPENAI_API_KEY: sk-YOURAPIKEY
history_file: chat_history.json
model: "gpt-4.1-mini"
presets:
  default:
    system_prompt: |
      You are a helpful assistant named Riko.
      You speak like a snarky anime girl.
      Always refer to the user as "senpai".

sovits_ping_config:
  text_lang: en
  prompt_lang : en
  ref_audio_path : D:\PyProjects\waifu_project\riko_project\character_files\main_sample.wav
  prompt_text : This is a sample voice for you to just get started with because it sounds kind of cute but just make sure this doesn't have long silences.
  
````

You can define personalities by modiying the config file.


## ğŸ› ï¸ Setup

### Install Dependencies

```bash
pip install uv 
uv pip install -r extra-req.txt
uv pip install -r requirements-client.txt
```

If you are also running the full GPT-SoVITS stack locally, you may need the larger dependency set in `requirements.txt` (it is intentionally heavy).

**If you want to use GPU support for Faster whisper** Make sure you also have:

* CUDA & cuDNN installed correctly (for Faster-Whisper GPU support)
* `ffmpeg` installed (for audio processing)


## ğŸ§ª Usage

### 1. Launch the GPT-SoVITS API 

### 2. Run the main script:


```bash
python server/main_chat.py
```

The flow:

1. Riko listens to your voice via microphone (push to talk)
2. Transcribes it with Faster-Whisper
3. Passes it to GPT (with history)
4. Generates a response
5. Synthesizes Riko's voice using GPT-SoVITS
6. Plays the output back to you


## ğŸ“Œ TODO / Future Improvements

* [ ] GUI or web interface
* [ ] Live microphone input support
* [ ] Emotion or tone control in speech synthesis
* [ ] VRM model frontend


## ğŸ§‘â€ğŸ¤ Credits

* Voice synthesis powered by [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)
* ASR via [Faster-Whisper](https://github.com/SYSTRAN/faster-whisper)
* Language model via [OpenAI GPT](https://platform.openai.com)


## ğŸ“œ License

MIT â€” feel free to clone, modify, and build your own waifu voice companion.


